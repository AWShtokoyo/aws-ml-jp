{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f24a09e9-262f-4943-84a2-b60b6c24c389",
   "metadata": {},
   "source": [
    "# OpenCALM SageMaker Inference\n",
    "\n",
    "This is a sample code to deploy [OpenCALM](https://huggingface.co/spaces/kyo-takano/OpenCALM-7B) on SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0428530b-8f42-4ab7-83ce-c3bdfa96a51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker>=2.143.0 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (2.164.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from sagemaker>=2.143.0) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from sagemaker>=2.143.0) (1.26.151)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from sagemaker>=2.143.0) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from sagemaker>=2.143.0) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from sagemaker>=2.143.0) (1.24.3)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from sagemaker>=2.143.0) (3.20.3)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from sagemaker>=2.143.0) (0.1.5)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from sagemaker>=2.143.0) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from sagemaker>=2.143.0) (4.13.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from sagemaker>=2.143.0) (23.1)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from sagemaker>=2.143.0) (2.0.2)\n",
      "Requirement already satisfied: pathos in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from sagemaker>=2.143.0) (0.3.0)\n",
      "Requirement already satisfied: schema in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from sagemaker>=2.143.0) (0.7.5)\n",
      "Requirement already satisfied: PyYAML==6.0 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from sagemaker>=2.143.0) (6.0)\n",
      "Requirement already satisfied: jsonschema in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from sagemaker>=2.143.0) (4.17.3)\n",
      "Requirement already satisfied: platformdirs in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from sagemaker>=2.143.0) (3.5.3)\n",
      "Requirement already satisfied: tblib==1.7.0 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from sagemaker>=2.143.0) (1.7.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.151 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker>=2.143.0) (1.29.151)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker>=2.143.0) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker>=2.143.0) (0.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker>=2.143.0) (3.15.0)\n",
      "Requirement already satisfied: six in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker>=2.143.0) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from jsonschema->sagemaker>=2.143.0) (0.19.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from pandas->sagemaker>=2.143.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from pandas->sagemaker>=2.143.0) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from pandas->sagemaker>=2.143.0) (2023.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from pathos->sagemaker>=2.143.0) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from pathos->sagemaker>=2.143.0) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from pathos->sagemaker>=2.143.0) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from pathos->sagemaker>=2.143.0) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from schema->sagemaker>=2.143.0) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ubuntu/miniconda3/envs/chatgpt/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.151->boto3<2.0,>=1.26.131->sagemaker>=2.143.0) (1.26.16)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"sagemaker>=2.143.0\" -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f94c4e8-de95-4657-97e0-dc213415bee5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.164.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker, boto3, json\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9882e8b3-4b8a-4700-8233-8f7e504c6b8d",
   "metadata": {},
   "source": [
    "## Package and Upload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a08d3c5f-2537-433b-a7c9-e2da3480a5f4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/environment/aws-ml-jp/tasks/generative-ai/text-to-text/fine-tuning/instruction-tuning/Transformers/scripts\n",
      "code/\n",
      "code/inference.py\n",
      "code/requirements.txt\n",
      "code/finetune.py\n",
      "code/run_clm.py\n",
      "code/templates/\n",
      "code/templates/simple_qa.json\n",
      "code/templates/alpaca_short.json\n",
      "code/templates/simple_qa2.json\n",
      "code/templates/rinna.json\n",
      "code/templates/alpaca.json\n",
      "code/templates/simple_qa_ja.json\n",
      "code/templates/stable_lm.json\n",
      "code/templates/.ipynb_checkpoints/\n",
      "code/templates/.ipynb_checkpoints/alpaca-checkpoint.json\n",
      "code/templates/.ipynb_checkpoints/simple_qa2-checkpoint.json\n",
      "code/templates/.ipynb_checkpoints/simple_qa_ja-checkpoint.json\n",
      "code/templates/.ipynb_checkpoints/simple_qa-checkpoint.json\n",
      "code/utils/\n",
      "code/utils/prompter.py\n",
      "code/utils/__init__.py\n",
      "code/.ipynb_checkpoints/\n",
      "code/.ipynb_checkpoints/inference-checkpoint.py\n",
      "code/__init__.py\n",
      "conftest.py\n",
      "tests/\n",
      "tests/environment.yml\n",
      "tests/utils/\n",
      "tests/utils/test_prompter.py\n",
      "tests/utils/__init__.py\n",
      "tests/__init__.py\n",
      "/home/ubuntu/environment/aws-ml-jp/tasks/generative-ai/text-to-text/fine-tuning/instruction-tuning/Transformers\n"
     ]
    }
   ],
   "source": [
    "!rm -rf scripts/model\n",
    "%cd scripts\n",
    "!tar -czvf ../package.tar.gz *\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11d0ae99-8cfe-43f5-8677-863e91bce7a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-585936743357/OpenCALM/package.tar.gz'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = sess.upload_data('package.tar.gz', bucket=bucket, key_prefix=f\"OpenCALM\")\n",
    "model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432b637-a883-4d94-ba28-54fc1be73408",
   "metadata": {},
   "source": [
    "## Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a20f1592-7ff0-45a2-bbb7-3f9528a11a98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "endpoint_name = \"OpenCALM\"\n",
    "\n",
    "huggingface_model = PyTorchModel(\n",
    "    model_data=model_path,\n",
    "    framework_version=\"1.13\",\n",
    "    py_version='py39',\n",
    "    role=role,\n",
    "    name=endpoint_name,\n",
    "    env={\n",
    "        \"model_params\": json.dumps({\n",
    "            \"base_model\": \"cyberagent/open-calm-7b\",\n",
    "            \"peft\": False,\n",
    "            \"load_8bit\": True,\n",
    "            \"prompt_template\": \"simple_qa_ja\",\n",
    "        })\n",
    "        \n",
    "    }\n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.g5.2xlarge',\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=JSONSerializer(),\n",
    "    async_inference_config=AsyncInferenceConfig()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07b0901-2675-49e5-8ccd-968f3ca2820e",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6eb4904-4b77-4cd0-bbe9-4d4685bc018e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ExpiredToken) when calling the PutObject operation: The provided token has expired.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 23\u001b[0m\n\u001b[1;32m      6\u001b[0m predictor_client \u001b[38;5;241m=\u001b[39m AsyncPredictor(\n\u001b[1;32m      7\u001b[0m     predictor\u001b[38;5;241m=\u001b[39mPredictor(\n\u001b[1;32m      8\u001b[0m         endpoint_name\u001b[38;5;241m=\u001b[39mendpoint_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     name\u001b[38;5;241m=\u001b[39mendpoint_name\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstruction\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m映画『ウエスト・サイド物語』に登場する2つの少年グループといえば、シャーク団と何団?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_new_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# \"stop_ids\": [50278, 50279, 50277, 1, 0],\u001b[39;00m\n\u001b[1;32m     22\u001b[0m }\n\u001b[0;32m---> 23\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/miniconda3/envs/chatgpt/lib/python3.10/site-packages/sagemaker/predictor_async.py:99\u001b[0m, in \u001b[0;36mAsyncPredictor.predict\u001b[0;34m(self, data, input_path, initial_args, inference_id, waiter_config)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease provide input data or input Amazon S3 location to use async prediction\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     input_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upload_data_to_s3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_path \u001b[38;5;241m=\u001b[39m input_path\n\u001b[1;32m    102\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_submit_async_request(input_path, initial_args, inference_id)\n",
      "File \u001b[0;32m~/miniconda3/envs/chatgpt/lib/python3.10/site-packages/sagemaker/predictor_async.py:179\u001b[0m, in \u001b[0;36mAsyncPredictor._upload_data_to_s3\u001b[0;34m(self, data, input_path)\u001b[0m\n\u001b[1;32m    171\u001b[0m     key \u001b[38;5;241m=\u001b[39m s3\u001b[38;5;241m.\u001b[39ms3_path_join(\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mdefault_bucket_prefix,\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync-endpoint-inputs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    174\u001b[0m         name_from_base(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, short\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(timestamp, my_uuid),\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    178\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserializer\u001b[38;5;241m.\u001b[39mserialize(data)\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms3_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mBody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mContentType\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCONTENT_TYPE\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m input_path \u001b[38;5;241m=\u001b[39m input_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3://\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(bucket, key)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m input_path\n",
      "File \u001b[0;32m~/miniconda3/envs/chatgpt/lib/python3.10/site-packages/botocore/client.py:530\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[1;32m    529\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/chatgpt/lib/python3.10/site-packages/botocore/client.py:964\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    962\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m parsed_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    963\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 964\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ExpiredToken) when calling the PutObject operation: The provided token has expired."
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.predictor_async import AsyncPredictor\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import NumpyDeserializer\n",
    "\n",
    "predictor_client = AsyncPredictor(\n",
    "    predictor=Predictor(\n",
    "        endpoint_name=endpoint_name,\n",
    "        sagemaker_session=sess,\n",
    "        serializer=JSONSerializer(),\n",
    "        deserializer=NumpyDeserializer()\n",
    "    ),\n",
    "    name=endpoint_name\n",
    ")\n",
    "data = {\n",
    "    \"instruction\": \"映画『ウエスト・サイド物語』に登場する2つの少年グループといえば、シャーク団と何団?\",\n",
    "    \"max_new_tokens\": 64,\n",
    "    \"temperature\": 0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": 1,\n",
    "    # \"stop_ids\": [50278, 50279, 50277, 1, 0],\n",
    "}\n",
    "response = predictor_client.predict(\n",
    "    data=data\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ebbfd-3b41-4305-95af-8d35c013969b",
   "metadata": {},
   "source": [
    "## Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd9be37-f988-4394-b920-61d1cfeaf066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34d15bf-6c19-4446-8108-f07c9b365f19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
